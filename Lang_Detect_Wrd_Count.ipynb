{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPUkrowSYjEeGV1kecNpKA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roberthouston14/Feature_Extractors/blob/main/Lang_Detect_Wrd_Count.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check GPU configuration\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "59y22zmgSJkR",
        "outputId": "e0e0eb08-278f-4f83-e851-0f775ca6f72f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVKtx7cbR6IZ",
        "outputId": "329ed753-30cb-4726-be3d-038d4f8b777d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the file location: /content/drive/MyDrive/Production Datasets/GOLD_DeDup.csv\n",
            "Enter the column name for labels: label\n",
            "Enter the column name for text: text\n",
            "Row 17371 contains meaningful text.\n",
            "Row 4685 contains meaningful text.\n",
            "Row 42268 contains meaningful text.\n",
            "Row 9714 contains meaningful text.\n",
            "Row 42626 contains meaningful text.\n",
            "Row 7910 contains meaningful text.\n",
            "Row 25942 contains meaningful text.\n",
            "Row 29124 contains meaningful text.\n",
            "Row 12057 contains meaningful text.\n",
            "Row 33186 contains meaningful text.\n",
            "Row 32932 contains meaningful text.\n",
            "Row 9902 contains meaningful text.\n",
            "Row 32917 contains meaningful text.\n",
            "Row 8986 contains meaningful text.\n",
            "Row 20279 contains meaningful text.\n",
            "Row 17960 contains meaningful text.\n"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# import spacy\n",
        "# import random\n",
        "\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# # Prompt user for the file location\n",
        "# file_path = input(\"Enter the file location: \")\n",
        "\n",
        "# # Load the .csv file as a DataFrame\n",
        "# df = pd.read_csv(file_path)\n",
        "\n",
        "# # Prompt user for the column names\n",
        "# label_column = input(\"Enter the column name for labels: \")\n",
        "# text_column = input(\"Enter the column name for text: \")\n",
        "\n",
        "# def has_meaningful_text(email_text):\n",
        "#     doc = nlp(email_text)\n",
        "#     noun_count = sum([1 for token in doc if token.pos_ == \"NOUN\"])\n",
        "#     return noun_count >= 10  # arbitrary threshold for number of nouns\n",
        "\n",
        "# # Downsample the dataset to select 25 rows at random\n",
        "# n_samples = 25\n",
        "# label_counts = df[label_column].value_counts()\n",
        "# n_samples_per_label = int(n_samples / 2)\n",
        "# label_1_rows = df[df[label_column] == 1].sample(n_samples_per_label)\n",
        "# label_0_rows = df[df[label_column] == 0].sample(n_samples_per_label)\n",
        "# df = pd.concat([label_1_rows, label_0_rows])\n",
        "\n",
        "# # Filter out irrelevant characters\n",
        "# df = df[df[text_column].apply(lambda x: has_meaningful_text(x))]\n",
        "\n",
        "# # Example usage\n",
        "# for i, row in df.iterrows():\n",
        "#     if has_meaningful_text(row[text_column]):\n",
        "#         print(f\"Row {i} contains meaningful text.\")\n",
        "#     else:\n",
        "#         print(f\"Row {i} does not contain meaningful text.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import pandas as pd\n",
        "# import spacy\n",
        "# import random\n",
        "\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# # Prompt user for the file location\n",
        "# file_path = input(\"Enter the file location: \")\n",
        "\n",
        "# # Load the .csv file as a DataFrame\n",
        "# df = pd.read_csv(file_path)\n",
        "\n",
        "# # Prompt user for the column names\n",
        "# label_column = input(\"Enter the column name for labels: \")\n",
        "# text_column = input(\"Enter the column name for text: \")\n",
        "\n",
        "# def has_meaningful_text(email_text):\n",
        "#     doc = nlp(email_text)\n",
        "#     noun_count = sum([1 for token in doc if token.pos_ == \"NOUN\"])\n",
        "#     return noun_count >= 10  # arbitrary threshold for number of nouns\n",
        "\n",
        "# # Filter out irrelevant characters\n",
        "# df_meaningful = df[df[text_column].apply(lambda x: has_meaningful_text(x))]\n",
        "\n",
        "# # Downsample the dataset to select 6000 rows at random\n",
        "# n_samples = 6000\n",
        "# label_counts = df_meaningful[label_column].value_counts()\n",
        "# n_samples_per_label = int(n_samples / 2)\n",
        "# label_1_rows = df_meaningful[df_meaningful[label_column] == 1].sample(n_samples_per_label)\n",
        "# label_0_rows = df_meaningful[df_meaningful[label_column] == 0].sample(n_samples_per_label)\n",
        "# df_sampled = pd.concat([label_1_rows, label_0_rows])\n",
        "\n",
        "# # Save the downsampled DataFrame as a new CSV file\n",
        "# output_file_path = os.path.splitext(file_path)[0] + \"_Dwn_Smpl_6000.csv\"\n",
        "# df_sampled.to_csv(output_file_path, index=False)\n",
        "\n",
        "# # Example usage\n",
        "# print(f\"The original DataFrame contains {len(df)} rows.\")\n",
        "# print(f\"The df_meaningful DataFrame contains {len(df_meaningful)} rows.\")\n",
        "# print(f\"The df_sampled DataFrame contains {len(df_sampled)} rows.\")\n",
        "# print(f\"The downsampled DataFrame has been saved to {output_file_path}.\")\n"
      ],
      "metadata": {
        "id": "OGEPlVXfopV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import random\n",
        "\n",
        "# # Prompt user for the file location\n",
        "# file_path = input(\"Enter the file location: \")\n",
        "\n",
        "# # Load the .csv file as a DataFrame\n",
        "# df = pd.read_csv(file_path)\n",
        "\n",
        "# # Prompt user for the column name\n",
        "# text_column = input(\"Enter the column name: \")\n",
        "\n",
        "# # Randomly sample 25 rows from the DataFrame\n",
        "# df_sample = df.sample(n=25, random_state=42)\n",
        "\n",
        "# # Count the number of words in each row of the specified column\n",
        "# df_sample[text_column+\"_wrd_count\"] = df_sample[text_column].apply(lambda x: len(x.split()))\n",
        "\n",
        "# # Example usage\n",
        "# print(f\"The original DataFrame contains {len(df)} rows.\")\n",
        "# print(f\"The new word count column is named '{text_column}_wrd_count'.\")\n",
        "# print(df_sample.head())\n"
      ],
      "metadata": {
        "id": "-NHjfdf7BV29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This script loads a .csv file as a pandas DataFrame, prompts the user for a text column name, \n",
        "randomly samples 25 rows from the DataFrame, and counts the number of words in each row of the specified column.\n",
        "The resulting DataFrame with the word count column added is then printed to the console.\n",
        "\n",
        "Author: Robert Houston\n",
        "Date: 3/19/2023\n",
        "\n",
        "Usage: python sample_and_count.py\n",
        "\n",
        "Requirements: pandas\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Prompt user for the file location\n",
        "file_path = input(\"Enter the file location: \")\n",
        "\n",
        "# Load the .csv file as a DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Prompt user for the column name\n",
        "text_column = input(\"Enter the column name: \")\n",
        "\n",
        "# Randomly sample 25 rows from the DataFrame\n",
        "df_sample = df.sample(n=25, random_state=42)\n",
        "\n",
        "# Count the number of words in each row of the specified column\n",
        "df_sample[text_column+\"_wrd_count\"] = df_sample[text_column].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Print summary of sampled and counted data\n",
        "print(f\"The original DataFrame contains {len(df)} rows.\")\n",
        "print(f\"The new word count column is named '{text_column}_wrd_count'.\")\n",
        "print(df_sample.head())"
      ],
      "metadata": {
        "id": "kDiECJyvX-xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langid"
      ],
      "metadata": {
        "id": "kY-4iRIGDNDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langdetect"
      ],
      "metadata": {
        "id": "a4_yHxdVGGoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Working Language Detection Code\n",
        "# import pandas as pd\n",
        "# from langdetect import detect_langs\n",
        "\n",
        "# # Prompt user for the file location\n",
        "# file_path = input(\"Enter the file location: \")\n",
        "\n",
        "# # Load the .csv file as a DataFrame\n",
        "# df = pd.read_csv(file_path)\n",
        "\n",
        "# # Prompt user for the column name\n",
        "# text_column = input(\"Enter the column name: \")\n",
        "\n",
        "# # Define function to check if text is in English\n",
        "# def is_english(text):\n",
        "#     try:\n",
        "#         languages = detect_langs(text)\n",
        "#         for lang in languages:\n",
        "#             if lang.lang == \"en\" and lang.prob > 0.90:\n",
        "#                 return True\n",
        "#         return False\n",
        "#     except:\n",
        "#         return False\n",
        "\n",
        "# # Drop rows that are not in English\n",
        "# df = df[df[text_column].apply(lambda x: is_english(x))]\n",
        "\n",
        "# # Example usage\n",
        "# print(f\"The modified DataFrame contains {len(df)} rows.\")\n",
        "# print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0Tr3bj2GWgG",
        "outputId": "1f5753dd-ea1d-4ac3-9d53-bb4123bc99ef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the file location: /content/drive/MyDrive/Production Datasets/GOLD_DeDup_Squeeky_Clean.csv\n",
            "Enter the column name: clean_stage_1\n",
            "The modified DataFrame contains 86 rows.\n",
            "                                   subject  \\\n",
            "0                      good question ( s )   \n",
            "2                                 re [ 8 ]   \n",
            "3  hey , it ' s me beckyvgko 968124 on msn   \n",
            "4  etc - theatre event - cirque due soleil   \n",
            "5       lst rev dec . 1999 josey ranch nom   \n",
            "\n",
            "                                                text  label  \\\n",
            "0                         i can answer some of these      0   \n",
            "2  yes , i don ' t mind outlaw star in 1990 ask o...      1   \n",
            "3  jkoutsi if the image above does not open pleas...      1   \n",
            "4  please note that i need headcount extra early ...      0   \n",
            "5  fyi forwarded by susan d trevino / hou / ect o...      0   \n",
            "\n",
            "                                       clean_stage_1  \\\n",
            "0                         i can answer some of these   \n",
            "2  yes , i don ' t mind outlaw star in 1990 ask o...   \n",
            "3  jkoutsi if the image above does not open pleas...   \n",
            "4  please note that i need headcount extra early ...   \n",
            "5  fyi forwarded by susan d trevino / hou / ect o...   \n",
            "\n",
            "                                          clean_text  JJ  NN  VB  \n",
            "0                                             answer   0   1   0  \n",
            "2     yes mind outlaw star 1990 ask therepoetry 1994   0   5   0  \n",
            "3  jkoutsi image open please go site important in...   4  12   2  \n",
            "4  please note need headcount extra early event !...  30  65  16  \n",
            "5  fyi forwarded susan trevino hou ect 12 15 99 0...  13  58  13  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "65e58kVyDi4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This script loads a .csv file as a pandas DataFrame, prompts the user for a text column name, and then drops all non-English rows in that column using the langdetect library. The cleaned DataFrame is saved in a new file with \"_Eng_Only\" appended to the original file name in the same directory as the source file.\n",
        "\n",
        "Author: Robert Houston\n",
        "Date: 3/19/2023\n",
        "Usage: python clean_text_data.py\n",
        "\n",
        "Requirements: pandas, langdetect\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from langdetect import detect_langs\n",
        "import os\n",
        "\n",
        "# Prompt user for the file location\n",
        "file_path = input(\"Enter the file location: \")\n",
        "\n",
        "# Load the .csv file as a DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Prompt user for the column name\n",
        "text_column = input(\"Enter the column name: \")\n",
        "\n",
        "# Define function to check if text is in English\n",
        "def is_english(text):\n",
        "    \"\"\"\n",
        "    This function takes a text string as input and returns True if it is in English, False otherwise.\n",
        "    It uses the langdetect library to detect the language of the text and checks if the detected language\n",
        "    is English with a probability score of at least 0.90.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        languages = detect_langs(text)\n",
        "        for lang in languages:\n",
        "            if lang.lang == \"en\" and lang.prob > 0.90:\n",
        "                return True\n",
        "        return False\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Drop rows that are not in English\n",
        "df = df[df[text_column].apply(lambda x: is_english(x))]\n",
        "\n",
        "# Save cleaned DataFrame to a new file\n",
        "filename, ext = os.path.splitext(file_path)\n",
        "new_filename = f\"{filename}_Eng_Only{ext}\"\n",
        "df.to_csv(new_filename, index=False)\n",
        "\n",
        "# Print summary of cleaned data\n",
        "print(f\"The modified DataFrame contains {len(df)} rows.\")\n",
        "print(df.head())\n",
        "\n",
        "# Print location of cleaned data file\n",
        "print(f\"The cleaned data has been saved in {new_filename}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuTEhXsJWV7E",
        "outputId": "dc585e99-4a26-485f-f65b-4280ebd1352d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the file location: /content/drive/MyDrive/Production Datasets/GOLD_DeDup_Squeeky_Clean.csv\n",
            "Enter the column name: text\n",
            "The modified DataFrame contains 86 rows.\n",
            "                                   subject  \\\n",
            "0                      good question ( s )   \n",
            "2                                 re [ 8 ]   \n",
            "3  hey , it ' s me beckyvgko 968124 on msn   \n",
            "4  etc - theatre event - cirque due soleil   \n",
            "5       lst rev dec . 1999 josey ranch nom   \n",
            "\n",
            "                                                text  label  \\\n",
            "0                         i can answer some of these      0   \n",
            "2  yes , i don ' t mind outlaw star in 1990 ask o...      1   \n",
            "3  jkoutsi if the image above does not open pleas...      1   \n",
            "4  please note that i need headcount extra early ...      0   \n",
            "5  fyi forwarded by susan d trevino / hou / ect o...      0   \n",
            "\n",
            "                                       clean_stage_1  \\\n",
            "0                         i can answer some of these   \n",
            "2  yes , i don ' t mind outlaw star in 1990 ask o...   \n",
            "3  jkoutsi if the image above does not open pleas...   \n",
            "4  please note that i need headcount extra early ...   \n",
            "5  fyi forwarded by susan d trevino / hou / ect o...   \n",
            "\n",
            "                                          clean_text  JJ  NN  VB  \n",
            "0                                             answer   0   1   0  \n",
            "2     yes mind outlaw star 1990 ask therepoetry 1994   0   5   0  \n",
            "3  jkoutsi image open please go site important in...   4  12   2  \n",
            "4  please note need headcount extra early event !...  30  65  16  \n",
            "5  fyi forwarded susan trevino hou ect 12 15 99 0...  13  58  13  \n",
            "The cleaned data has been saved in /content/drive/MyDrive/Production Datasets/GOLD_DeDup_Squeeky_Clean_Eng_Only.csv.\n"
          ]
        }
      ]
    }
  ]
}